from collections import deque, defaultdict
import os
import logging
import time
import json
import mindspore as ms
from mindspore import Tensor, ops
import numpy as np
import mindspore.context as context

from model import Semantic_Mapping
from envs import make_ue5_envs_fbe
from arguments import get_args

os.environ["OMP_NUM_THREADS"] = "1"
zeros = ops.Zeros()
fill = ops.Fill()
ones = ops.Ones()


def main():
    args = get_args()

    np.random.seed(args.seed)
    minval = Tensor(1.0, ms.float32)
    maxval = Tensor(2.0, ms.float32)
    ops.uniform((1, 4), minval, maxval, seed=args.seed)

    # Setup Logging
    log_dir = "{}/models/{}/".format(args.dump_location, args.exp_name)
    dump_dir = "{}/dump/{}/".format(args.dump_location, args.exp_name)

    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    if not os.path.exists(dump_dir):
        os.makedirs(dump_dir)

    logging.basicConfig(
        filename=log_dir + 'train.log',
        level=logging.INFO)
    print("Dumping at {}".format(log_dir))
    print(args)
    logging.info(args)

    # Logging and loss variables
    args.num_processes = 1
    num_scenes = args.num_processes
    num_episodes = int(args.num_eval_episodes)
    ms.set_context(device_id=0)
    # device = "cuda:0"

    g_masks = ones(num_scenes, ms.float32)

    episode_success = []
    episode_spl = []
    episode_dist = []
    for _ in range(args.num_processes):
        episode_success.append(deque(maxlen=num_episodes))
        episode_spl.append(deque(maxlen=num_episodes))
        episode_dist.append(deque(maxlen=num_episodes))

    finished = np.zeros((args.num_processes))
    wait_env = np.zeros((args.num_processes))

    # Starting environments
    envs = make_ue5_envs_fbe(args)
    obs, infos = envs.reset()
    camera_param = envs.get_camera_parameters()
    obs = ms.Tensor(obs).unsqueeze(0)
    infos = [infos]

    # Initialize map variables:
    # Full map consists of multiple channels containing the following:
    # 1. Obstacle Map
    # 2. Exploread Area
    # 3. Current Agent Location
    # 4. Past Agent Locations
    # 5,6,7,.. : Semantic Categories
    nc = args.num_sem_categories + 4  # num channels

    # Calculating full and local map sizes
    map_size = args.map_size_cm // args.map_resolution
    full_w, full_h = map_size, map_size
    local_w = int(full_w / args.global_downscaling)
    local_h = int(full_h / args.global_downscaling)

    # Initializing full and local map
    full_map = zeros((num_scenes, nc, full_w, full_h), ms.float32)
    local_map = zeros((num_scenes, nc, local_w, local_h), ms.float32)

    # Initial full and local pose
    full_pose = zeros((num_scenes, 3), ms.float32)
    local_pose = zeros((num_scenes, 3), ms.float32)

    # Origin of local map
    origins = np.zeros((num_scenes, 3))

    # Local Map Boundaries
    lmb = np.zeros((num_scenes, 4)).astype(int)

    # Planner pose inputs has 7 dimensions
    # 1-3 store continuous global agent location
    # 4-7 store local map boundaries
    planner_pose_inputs = np.zeros((num_scenes, 7))

    def get_local_map_boundaries(agent_loc, local_sizes, full_sizes):
        loc_r, loc_c = agent_loc
        local_w, local_h = local_sizes
        full_w, full_h = full_sizes

        if args.global_downscaling > 1:
            gx1, gy1 = loc_r - local_w // 2, loc_c - local_h // 2
            gx2, gy2 = gx1 + local_w, gy1 + local_h
            if gx1 < 0:
                gx1, gx2 = 0, local_w
            if gx2 > full_w:
                gx1, gx2 = full_w - local_w, full_w

            if gy1 < 0:
                gy1, gy2 = 0, local_h
            if gy2 > full_h:
                gy1, gy2 = full_h - local_h, full_h
        else:
            gx1, gx2, gy1, gy2 = 0, full_w, 0, full_h

        return [gx1, gx2, gy1, gy2]

    def init_map_and_pose():
        full_map = fill(ms.float32, (num_scenes, nc, full_w, full_h), 0)
        full_pose = fill(ms.float32, (num_scenes, 3), 0)
        full_pose[:, :2] = args.map_size_cm / 100.0 / 2.0

        locs = full_pose.numpy()
        planner_pose_inputs[:, :3] = locs
        for e in range(num_scenes):
            r, c = locs[e, 1], locs[e, 0]
            loc_r, loc_c = [int(r * 100.0 / args.map_resolution),
                            int(c * 100.0 / args.map_resolution)]

            full_map[e, 2:4, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.0

            lmb[e] = get_local_map_boundaries((loc_r, loc_c),
                                              (local_w, local_h),
                                              (full_w, full_h))

            planner_pose_inputs[e, 3:] = lmb[e]
            origins[e] = [lmb[e][2] * args.map_resolution / 100.0,
                          lmb[e][0] * args.map_resolution / 100.0, 0.]

        for e in range(num_scenes):
            local_map[e] = full_map[e, :,
                                    int(lmb[e, 0]):int(lmb[e, 1]),
                                    int(lmb[e, 2]):int(lmb[e, 3])]
            local_pose[e] = full_pose[e] - \
                ms.Tensor(origins[e], ms.float32)

    def init_map_and_pose_for_env(e):
        full_map[e] = fill(ms.float32, (nc, full_w, full_h), 0)
        full_pose[e] = fill(ms.float32, (1, 3), 0)[0]
        full_pose[e, :2] = args.map_size_cm / 100.0 / 2.0

        locs = full_pose[e].numpy()
        planner_pose_inputs[e, :3] = locs
        r, c = locs[1], locs[0]
        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),
                        int(c * 100.0 / args.map_resolution)]

        full_map[e, 2:4, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.0

        lmb[e] = get_local_map_boundaries((loc_r, loc_c),
                                          (local_w, local_h),
                                          (full_w, full_h))

        planner_pose_inputs[e, 3:] = lmb[e]
        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,
                      lmb[e][0] * args.map_resolution / 100.0, 0.]

        local_map[e] = full_map[e, :, int(lmb[e, 0]):int(lmb[e, 1]), int(lmb[e, 2]):int(lmb[e, 3])]
        local_pose[e] = full_pose[e] - \
            ms.Tensor(origins[e], ms.float32)

    def update_intrinsic_rew(e):
        prev_explored_area = full_map[e, 1].sum(1).sum(0)
        full_map[e, :, int(lmb[e, 0]):int(lmb[e, 1]), int(lmb[e, 2]):int(lmb[e, 3])] = local_map[e]
        curr_explored_area = full_map[e, 1].sum(1).sum(0)
        intrinsic_rews[e] = curr_explored_area - prev_explored_area
        intrinsic_rews[e] *= (args.map_resolution / 100.)**2  # to m^2

    init_map_and_pose()
    free_local_map = local_map.copy()
    free_local_map[0, 0, int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4,
    int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4] = 1.

    # Semantic Mapping
    sem_map_module = Semantic_Mapping(args)
    free_sem_map_module = Semantic_Mapping(args, max_height=20, min_height=-150)

    intrinsic_rews = zeros(num_scenes, ms.float32)

    # Predict semantic map from frame 1
    poses = ms.Tensor(np.asarray(
        [infos[env_idx]['sensor_pose'] for env_idx in range(num_scenes)]), ms.float32
    )

    local_pose2 = local_pose.copy()
    _, local_map, _, local_pose = \
        sem_map_module(obs, poses, local_map, local_pose, camera_param)
    _, free_local_map, _, _ = \
        free_sem_map_module(obs, poses, free_local_map, local_pose2, camera_param)

    # Compute Global policy input
    locs = local_pose.numpy()

    for e in range(num_scenes):
        r, c = locs[e, 1], locs[e, 0]
        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),
                        int(c * 100.0 / args.map_resolution)]

        local_map[e, 2:4, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.

    free_local_map[0, 0, int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4,
    int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4] = 1.

    goal_cat_id = ms.Tensor(np.asarray(
        [infos[env_idx]['goal_cat_id'] for env_idx
         in range(num_scenes)]), ms.float32)

    goal_maps = [np.zeros((local_w, local_h)) for _ in range(num_scenes)]

    planner_inputs = [{} for e in range(num_scenes)]
    for e, p_input in enumerate(planner_inputs):
        p_input['map_pred'] = local_map[e, 0, :, :].numpy()
        p_input['exp_pred'] = local_map[e, 1, :, :].numpy()
        p_input['free_pred'] = free_local_map[e, 0, :, :].numpy()
        p_input['pose_pred'] = planner_pose_inputs[e]
        p_input['goal'] = goal_maps[e]  # global_goals[e]
        p_input['new_goal'] = 1
        p_input['found_goal'] = 0
        p_input['wait'] = wait_env[e] or finished[e]
        if args.visualize or args.print_images:
            local_map[e, -1, :, :] = 1e-5
            p_input['sem_map_pred'] = local_map[e, 4:, :, :
                                                ].argmax(0).numpy()

    planner_inputs = planner_inputs[0]
    obs, _, done, infos, new_goal = envs.plan_act_and_preprocess(planner_inputs)
    camera_param = envs.get_camera_parameters()
    obs = ms.Tensor(obs, ms.float32).unsqueeze(0)
    infos = [infos]
    done = [done]
    planner_inputs['goal'] = new_goal

    start = time.time()

    spl_per_category = defaultdict(list)
    success_per_category = defaultdict(list)

    for step in range(args.num_training_frames // args.num_processes + 1):
        if finished.sum() == args.num_processes:
            break

        g_step = (step // args.num_local_steps) % args.num_global_steps
        l_step = step % args.num_local_steps
        reset_new_goal = False

        # ------------------------------------------------------------------
        # Reinitialize variables when episode ends
        l_masks = Tensor([0 if x else 1 for x in done], ms.float32)
        g_masks *= l_masks

        for e, x in enumerate(done):
            if x:
                logging.info('\n{}'.format(infos[e]))
                spl = infos[e]['spl']
                success = infos[e]['success']
                dist = infos[e]['distance_to_goal']
                spl_per_category[infos[e]['goal_name']].append(spl)
                success_per_category[infos[e]['goal_name']].append(success)
                if args.eval:
                    episode_success[e].append(success)
                    episode_spl[e].append(spl)
                    episode_dist[e].append(dist)
                    if len(episode_success[e]) == num_episodes:
                        finished[e] = 1
                else:
                    episode_success.append(success)
                    episode_spl.append(spl)
                    episode_dist.append(dist)
                wait_env[e] = 1.
                update_intrinsic_rew(e)
                init_map_and_pose_for_env(e)
                free_local_map = local_map.copy()
                new_goal = np.zeros((local_w, local_h))
                reset_new_goal = True
                obs, infos = envs.reset()
                camera_param = envs.get_camera_parameters()
                obs = ms.Tensor(obs, ms.float32).unsqueeze(0)
                infos = [infos]
                wait_env[e] = 0.
        # ------------------------------------------------------------------

        # ------------------------------------------------------------------
        # Semantic Mapping Module
        poses = ms.Tensor(np.asarray(
            [infos[env_idx]['sensor_pose'] for env_idx in range(num_scenes)]), ms.float32
        )

        local_pose2 = local_pose.copy()
        _, local_map, _, local_pose = \
            sem_map_module(obs, poses, local_map, local_pose, camera_param)
        _, free_local_map, _, _ = \
            free_sem_map_module(obs, poses, free_local_map, local_pose2, camera_param)

        locs = local_pose.numpy()
        planner_pose_inputs[:, :3] = locs + origins
        # Resetting current location channel
        local_map[:, 2, :, :] = fill(ms.float32, (num_scenes, local_w, local_h), 0)
        for e in range(num_scenes):
            r, c = locs[e, 1], locs[e, 0]
            loc_r, loc_c = [int(r * 100.0 / args.map_resolution),
                            int(c * 100.0 / args.map_resolution)]
            local_map[e, 2:4, loc_r - 2:loc_r + 3, loc_c - 2:loc_c + 3] = 1.

        free_local_map[0, 0, int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4,
        int(args.map_size_cm / 10) - 3:int(args.map_size_cm / 10) + 4] = 1.

        # ------------------------------------------------------------------

        # ------------------------------------------------------------------
        # Update long-term goal if target object is found
        found_goal = [0 for _ in range(num_scenes)]
        # goal_maps = [np.zeros((local_w, local_h)) for _ in range(num_scenes)]
        goal_maps = [new_goal]

        for e in range(num_scenes):
            cn = infos[e]['goal_cat_id'] + 4
            if local_map[e, cn, :, :].sum() != 0.:
                cat_semantic_map = local_map[e, cn, :, :].numpy()
                cat_semantic_scores = cat_semantic_map
                cat_semantic_scores[cat_semantic_scores > 0] = 1.
                goal_maps[e] = cat_semantic_scores
                found_goal[e] = 1
        # ------------------------------------------------------------------

        # ------------------------------------------------------------------
        # Take action and get next observation
        planner_inputs = [{} for e in range(num_scenes)]
        for e, p_input in enumerate(planner_inputs):
            p_input['map_pred'] = local_map[e, 0, :, :].numpy()
            p_input['exp_pred'] = local_map[e, 1, :, :].numpy()
            p_input['free_pred'] = free_local_map[e, 0, :, :].numpy()
            p_input['pose_pred'] = planner_pose_inputs[e]
            p_input['goal'] = goal_maps[e]  # global_goals[e]
            p_input['new_goal'] = (l_step == args.num_local_steps - 1) or reset_new_goal
            p_input['found_goal'] = found_goal[e]
            p_input['wait'] = wait_env[e] or finished[e]
            if args.visualize or args.print_images:
                local_map[e, -1, :, :] = 1e-5
                p_input['sem_map_pred'] = local_map[e, 4:, :,
                                                    :].argmax(0).numpy()

        planner_inputs = planner_inputs[0]
        obs, _, done, infos, new_goal = envs.plan_act_and_preprocess(planner_inputs)
        camera_param = envs.get_camera_parameters()
        obs = ms.Tensor(obs, ms.float32).unsqueeze(0)
        infos = [infos]
        done = [done]
        planner_inputs['goal'] = new_goal
        # ------------------------------------------------------------------

        # ------------------------------------------------------------------
        # Logging
        if step % args.log_interval == 0:
            end = time.time()
            time_elapsed = time.gmtime(end - start)
            log = " ".join([
                "Time: {0:0=2d}d".format(time_elapsed.tm_mday - 1),
                "{},".format(time.strftime("%Hh %Mm %Ss", time_elapsed)),
                "num timesteps {},".format(step * num_scenes),
                "FPS {},".format(int(step * num_scenes / (end - start)))
            ])

            log += "\n\t"

            if args.eval:
                total_success = []
                total_spl = []
                total_dist = []
                for e in range(args.num_processes):
                    for acc in episode_success[e]:
                        total_success.append(acc)
                    for dist in episode_dist[e]:
                        total_dist.append(dist)
                    for spl in episode_spl[e]:
                        total_spl.append(spl)

                if len(total_spl) > 0:
                    log += " ObjectNav succ/spl/dtg:"
                    log += " {:.3f}/{:.3f}/{:.3f}({:.0f}),".format(
                        np.mean(total_success),
                        np.mean(total_spl),
                        np.mean(total_dist),
                        len(total_spl))
            else:
                if len(episode_success) > 100:
                    log += " ObjectNav succ/spl/dtg:"
                    log += " {:.3f}/{:.3f}/{:.3f}({:.0f}),".format(
                        np.mean(episode_success),
                        np.mean(episode_spl),
                        np.mean(episode_dist),
                        len(episode_spl))

            print(log)
            logging.info(log)
        # ------------------------------------------------------------------

    # Print and save model performance numbers during evaluation
    if args.eval:
        print("Dumping eval details...")
        
        total_success = []
        total_spl = []
        total_dist = []
        for e in range(args.num_processes):
            for acc in episode_success[e]:
                total_success.append(acc)
            for dist in episode_dist[e]:
                total_dist.append(dist)
            for spl in episode_spl[e]:
                total_spl.append(spl)

        if len(total_spl) > 0:
            log = "Final ObjectNav succ/spl/dtg:"
            log += " {:.3f}/{:.3f}/{:.3f}({:.0f}),".format(
                np.mean(total_success),
                np.mean(total_spl),
                np.mean(total_dist),
                len(total_spl))

        print(log)
        logging.info(log)
            
        # Save the spl per category
        log = "Success | SPL per category\n"
        for key in success_per_category:
            log += "{}: {} | {}\n".format(key,
                                          sum(success_per_category[key]) /
                                          len(success_per_category[key]),
                                          sum(spl_per_category[key]) /
                                          len(spl_per_category[key]))

        print(log)
        logging.info(log)

        with open('{}/{}_spl_per_cat_pred_thr.json'.format(
                dump_dir, args.split), 'w') as f:
            json.dump(spl_per_category, f)

        with open('{}/{}_success_per_cat_pred_thr.json'.format(
                dump_dir, args.split), 'w') as f:
            json.dump(success_per_category, f)


if __name__ == "__main__":
    main()
